{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcJysqsvwLFc"
      },
      "source": [
        "# Reader & Writer\n",
        "##### Objetivos\n",
        "1. Leer de CSV\n",
        "1. Leer de JSON\n",
        "1. Escribir DataFrames a ficheros\n",
        "1. Escribir DataFrames a tables\n",
        "\n",
        "##### Métodos\n",
        "- <a href=\"https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql.html#input-and-output\" target=\"_blank\">DataFrameReader</a>: **`csv`**, **`json`**, **`option`**, **`schema`**\n",
        "- <a href=\"https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql.html#input-and-output\" target=\"_blank\">DataFrameWriter</a>: **`mode`**, **`option`**, **`parquet`**, **`format`**, **`saveAsTable`**\n",
        "- <a href=\"https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.types.StructType.html#pyspark.sql.types.StructType\" target=\"_blank\">StructType</a>: **`toDDL`**\n",
        "\n",
        "##### Spark Types\n",
        "- <a href=\"https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql.html#data-types\" target=\"_blank\">Types</a>: **`ArrayType`**, **`DoubleType`**, **`IntegerType`**, **`LongType`**, **`StringType`**, **`StructType`**, **`StructField`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afMHglFxwCr5",
        "outputId": "d1346688-5287-4079-f159-483ef415a91f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425345 sha256=230024f4f598e9258e19432d1c8d1c201f85dd6c46b567e48264ee1d95b1d6bf\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.0\n"
          ]
        }
      ],
      "source": [
        "%pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ep6PJgNzwFQB"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark import SparkContext\n",
        "\n",
        "spark = SparkSession.builder.master('local[*]').appName('reader-writer').getOrCreate()\n",
        "sc = SparkContext.getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1C9DPyITwoR8"
      },
      "source": [
        "## DataFrameReader\n",
        "Interfaz utilizada para cargar un DataFrame desde sistemas de almacenamiento externos.\n",
        "\n",
        "**`spark.read.parquet(\"ruta/a/archivos\")`**\n",
        "\n",
        "DataFrameReader es accesible a través del atributo **`read`** de SparkSession. Esta clase incluye métodos para cargar DataFrames desde diferentes sistemas de almacenamiento externos.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcPmtVR9wzJO"
      },
      "source": [
        "### Leer desde archivos CSV\n",
        "Leer desde un archivo CSV con el método **`csv`** de DataFrameReader y las siguientes opciones:\n",
        "\n",
        "Separador de tabulaciones, utilizar la primera línea como encabezado, inferir esquema\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-NfjaDzwpWH"
      },
      "outputs": [],
      "source": [
        "df = (spark\n",
        "  .read\n",
        "  .option('sep', ',')\n",
        "  .option('header', True)\n",
        "  .option('inferSchema', True)\n",
        "  .csv('/content/sample_data/california_housing_test.csv')\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "084AKrT7xOjs",
        "outputId": "31dfdbf9-58f1-4c89-a306-e2ec32f6ef2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- longitude: double (nullable = true)\n",
            " |-- latitude: double (nullable = true)\n",
            " |-- housing_median_age: double (nullable = true)\n",
            " |-- total_rooms: double (nullable = true)\n",
            " |-- total_bedrooms: double (nullable = true)\n",
            " |-- population: double (nullable = true)\n",
            " |-- households: double (nullable = true)\n",
            " |-- median_income: double (nullable = true)\n",
            " |-- median_house_value: double (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rekGDglxSR1l",
        "outputId": "deab3530-bb77-4961-8235-6f0fd5921b05"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "StructType([StructField('longitude', DoubleType(), True), StructField('latitude', DoubleType(), True), StructField('housing_median_age', DoubleType(), True), StructField('total_rooms', DoubleType(), True), StructField('total_bedrooms', DoubleType(), True), StructField('population', DoubleType(), True), StructField('households', DoubleType(), True), StructField('median_income', DoubleType(), True), StructField('median_house_value', DoubleType(), True)])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8lZkxnbxrBq",
        "outputId": "3e2dd9e3-2e6c-4a4a-d7e8-ec39f42f98ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- longitude: double (nullable = true)\n",
            " |-- latitude: double (nullable = true)\n",
            " |-- housing_median_age: double (nullable = true)\n",
            " |-- total_rooms: double (nullable = true)\n",
            " |-- total_bedrooms: double (nullable = true)\n",
            " |-- population: double (nullable = true)\n",
            " |-- households: double (nullable = true)\n",
            " |-- median_income: double (nullable = true)\n",
            " |-- median_house_value: double (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df2 = (spark\n",
        "       .read\n",
        "       .csv('/content/sample_data/california_housing_test.csv', sep=',', header=True, inferSchema=True)\n",
        ")\n",
        "\n",
        "df2.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uiT1QG75yDI5"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.types import DoubleType, StructType, StructField\n",
        "\n",
        "user_defined_schema = StructType([\n",
        "    StructField(\"longitude\", DoubleType(), True),\n",
        "    StructField(\"latitude\", DoubleType(), True),\n",
        "    StructField(\"housing_median_age\", DoubleType(), True),\n",
        "    StructField(\"total_rooms\", DoubleType(), True),\n",
        "    StructField(\"total_bedrooms\", DoubleType(), True),\n",
        "    StructField(\"population\", DoubleType(), True),\n",
        "    StructField(\"households\", DoubleType(), True),\n",
        "    StructField(\"median_income\", DoubleType(), True),\n",
        "    StructField(\"median_house_value\", DoubleType(), True)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4VW682eyiuY",
        "outputId": "0998bd30-99e8-4c97-e580-4efba10a3254"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- longitude: double (nullable = true)\n",
            " |-- latitude: double (nullable = true)\n",
            " |-- housing_median_age: double (nullable = true)\n",
            " |-- total_rooms: double (nullable = true)\n",
            " |-- total_bedrooms: double (nullable = true)\n",
            " |-- population: double (nullable = true)\n",
            " |-- households: double (nullable = true)\n",
            " |-- median_income: double (nullable = true)\n",
            " |-- median_house_value: double (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df3 = (\n",
        "    spark\n",
        "    .read\n",
        "    .option('sep', ',')\n",
        "    .option('header', True)\n",
        "    .schema(user_defined_schema)\n",
        "    .csv('/content/sample_data/california_housing_test.csv')\n",
        ")\n",
        "\n",
        "df3.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbAHl1vqy2qE",
        "outputId": "a0925897-6d56-4eeb-da79-b0b16477f5b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- longitude: double (nullable = true)\n",
            " |-- latitude: double (nullable = true)\n",
            " |-- housing_median_age: double (nullable = true)\n",
            " |-- total_rooms: double (nullable = true)\n",
            " |-- total_bedrooms: double (nullable = true)\n",
            " |-- population: double (nullable = true)\n",
            " |-- households: double (nullable = true)\n",
            " |-- median_income: double (nullable = true)\n",
            " |-- median_house_value: double (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "ddl_schema = \"longitude double, latitude double, housing_median_age double, total_rooms double, total_bedrooms double, population double, households double, median_income double, median_house_value double\"\n",
        "\n",
        "df4 = (\n",
        "    spark\n",
        "    .read\n",
        "    .option('sep', ',')\n",
        "    .option('header', True)\n",
        "    .schema(ddl_schema)\n",
        "    .csv('/content/sample_data/california_housing_test.csv')\n",
        ")\n",
        "\n",
        "df4.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9N06h-1xzaT-"
      },
      "source": [
        "### Leer de ficheros JSON"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NosJxRmozT4o",
        "outputId": "762b4d33-ed6a-45ba-f3d8-0af61c171e07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+----+-----+---------------+\n",
            "|Series|   X|    Y|_corrupt_record|\n",
            "+------+----+-----+---------------+\n",
            "|  NULL|NULL| NULL|              [|\n",
            "|     I|10.0| 8.04|           NULL|\n",
            "|     I| 8.0| 6.95|           NULL|\n",
            "|     I|13.0| 7.58|           NULL|\n",
            "|     I| 9.0| 8.81|           NULL|\n",
            "|     I|11.0| 8.33|           NULL|\n",
            "|     I|14.0| 9.96|           NULL|\n",
            "|     I| 6.0| 7.24|           NULL|\n",
            "|     I| 4.0| 4.26|           NULL|\n",
            "|     I|12.0|10.84|           NULL|\n",
            "|     I| 7.0| 4.81|           NULL|\n",
            "|     I| 5.0| 5.68|           NULL|\n",
            "|    II|10.0| 9.14|           NULL|\n",
            "|    II| 8.0| 8.14|           NULL|\n",
            "|    II|13.0| 8.74|           NULL|\n",
            "|    II| 9.0| 8.77|           NULL|\n",
            "|    II|11.0| 9.26|           NULL|\n",
            "|    II|14.0|  8.1|           NULL|\n",
            "|    II| 6.0| 6.13|           NULL|\n",
            "|    II| 4.0|  3.1|           NULL|\n",
            "+------+----+-----+---------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df5 = (\n",
        "    spark\n",
        "    .read\n",
        "    .option('inferSchema', True)\n",
        "    .json('/content/sample_data/anscombe.json')\n",
        ")\n",
        "\n",
        "df5.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9C7YiuCz6S6"
      },
      "source": [
        "### DataFrameWriter\n",
        "\n",
        "Interfaz usada para escribir un DataFrame en sistemas de almacenamiento externo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHzBdeYuznlx",
        "outputId": "7f575cf0-f7cc-4c2a-8e1b-eb1c771df35a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "spark.sql('create database db_dfw')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPD9fPzgVayv",
        "outputId": "bdccc7c0-d589-4642-978f-13b51a73e508"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+\n",
            "|namespace|\n",
            "+---------+\n",
            "|   db_dfw|\n",
            "|  default|\n",
            "+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql('show databases').show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZAtu4jCI0OyO"
      },
      "outputs": [],
      "source": [
        "df5.write.mode('overwrite').saveAsTable('db_dfw.anscombe')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Nuo-QOE0VKx",
        "outputId": "53a305d8-ce95-4c3a-90b7-844ab26c8488"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+----+-----+---------------+\n",
            "|Series|   X|    Y|_corrupt_record|\n",
            "+------+----+-----+---------------+\n",
            "|  NULL|NULL| NULL|              [|\n",
            "|     I|10.0| 8.04|           NULL|\n",
            "|     I| 8.0| 6.95|           NULL|\n",
            "|     I|13.0| 7.58|           NULL|\n",
            "|     I| 9.0| 8.81|           NULL|\n",
            "|     I|11.0| 8.33|           NULL|\n",
            "|     I|14.0| 9.96|           NULL|\n",
            "|     I| 6.0| 7.24|           NULL|\n",
            "|     I| 4.0| 4.26|           NULL|\n",
            "|     I|12.0|10.84|           NULL|\n",
            "|     I| 7.0| 4.81|           NULL|\n",
            "|     I| 5.0| 5.68|           NULL|\n",
            "|    II|10.0| 9.14|           NULL|\n",
            "|    II| 8.0| 8.14|           NULL|\n",
            "|    II|13.0| 8.74|           NULL|\n",
            "|    II| 9.0| 8.77|           NULL|\n",
            "|    II|11.0| 9.26|           NULL|\n",
            "|    II|14.0|  8.1|           NULL|\n",
            "|    II| 6.0| 6.13|           NULL|\n",
            "|    II| 4.0|  3.1|           NULL|\n",
            "+------+----+-----+---------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql('select * from db_dfw.anscombe').show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
